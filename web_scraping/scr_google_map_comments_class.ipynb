{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "匯入套件\n",
    "'''\n",
    "\n",
    "# 操作 browser 的 API\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# 處理逾時例外的工具\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# 面對動態網頁，等待某個元素出現的工具，通常與 exptected_conditions 搭配\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# 搭配 WebDriverWait 使用，對元素狀態的一種期待條件，若條件發生，則等待結束，往下一行執行\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# 期待元素出現要透過什麼方式指定，通常與 EC、WebDriverWait 一起使用\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 強制等待 (執行期間休息一下)\n",
    "from time import sleep\n",
    "\n",
    "# 美麗湯\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# 整理 json 使用的工具\n",
    "import json\n",
    "\n",
    "#正規表達式\n",
    "import re\n",
    "\n",
    "# 發送請求\n",
    "import requests\n",
    "\n",
    "# 讀取清單\n",
    "import csv\n",
    "\n",
    "# 整理時間格式\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# 執行 command 的時候用的\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "建立類別\n",
    "'''\n",
    "\n",
    "class GoogleMapScraper:\n",
    "    # 建構子\n",
    "    def __init__(self):\n",
    "        # 開啟瀏覽器\n",
    "        self.driver = self._init_driver()\n",
    "        # 先開啟 Google Maps\n",
    "        self.driver.get(\"https://www.google.com/maps?authuser=0\")\n",
    "        # 等待地圖加載\n",
    "        sleep(5)\n",
    "        # 爬取地點失敗log檔名\n",
    "        self.failed_locations = \"failed_locations.csv\"\n",
    "        # 用來存儲 google_2s 碼\n",
    "        self.checkpoint_file = \"google_2s_checkpoint.json\"  \n",
    "\n",
    "    # 開啟瀏覽器\n",
    "    def _init_driver(self):\n",
    "        # 啟動瀏覽器工具的選項\n",
    "        my_options = webdriver.ChromeOptions()\n",
    "        # my_options.add_argument(\"--headless\")              #不開啟實體瀏覽器背景執行\n",
    "        my_options.add_argument(\"--start-maximized\")         #最大化視窗\n",
    "        my_options.add_argument(\"--incognito\")               #開啟無痕模式\n",
    "        my_options.add_argument(\"--disable-popup-blocking\")  #禁用彈出攔截\n",
    "        my_options.add_argument(\"--disable-notifications\")   #取消 chrome 推播通知\n",
    "        my_options.add_argument(\"--lang=zh-TW\")              #設定為正體中文\n",
    "        my_options.add_argument(f\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\")\n",
    "        # 加入其他可能有用的隱私設定\n",
    "        my_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        my_options.add_argument('--disable-extensions')\n",
    "        my_options.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "        my_options.add_experimental_option('useAutomationExtension', False)\n",
    "        # 使用 Chrome 的 WebDriver\n",
    "        return webdriver.Chrome(options=my_options)\n",
    "    \n",
    "    # 爬取地點失敗log\n",
    "    def log_failed_location(self, location, reason):\n",
    "        with open(self.failed_locations, mode='a', encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([location, reason])\n",
    "    \n",
    "    # 搜尋地點\n",
    "    def search_location(self, location: str):\n",
    "        try:\n",
    "            # 等待搜尋框出現\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'input#searchboxinput'))\n",
    "            )\n",
    "            # 尋找網頁中的搜尋框\n",
    "            input_element = self.driver.find_element(By.CSS_SELECTOR, 'input#searchboxinput')\n",
    "            \n",
    "            # 在搜尋框中輸入文字\n",
    "            input_element.clear()\n",
    "            input_element.send_keys(location)\n",
    "\n",
    "            # 睡個幾秒\n",
    "            sleep(2)\n",
    "\n",
    "            # 尋找送出按鈕\n",
    "            clickButton = self.driver.find_element(\n",
    "                By.CSS_SELECTOR, 'button#searchbox-searchbutton'\n",
    "            )\n",
    "\n",
    "            # 送出搜尋\n",
    "            clickButton.click()\n",
    "\n",
    "            # 睡個幾秒 等url跳轉為包含1s碼的url\n",
    "            sleep(5)\n",
    "\n",
    "            # 回傳包含1s碼的url\n",
    "            return self.driver.current_url\n",
    "        \n",
    "        except:\n",
    "            # 搜尋失敗紀錄\n",
    "            print(f\"{location}:搜尋失敗\")\n",
    "            self.log_failed_location(location, \"搜尋失敗\")\n",
    "            return None\n",
    "    \n",
    "    # 取得地點的1s碼與身分驗證的KEI碼\n",
    "    def extract_google_codes(self, url: str):\n",
    "        try:\n",
    "            # 用正則表達式轉換地點的1s碼\n",
    "            google_1s = re.findall(r'0x\\w+', url)\n",
    "            if len(google_1s) >= 2:\n",
    "                google_1s_code = f\"{google_1s[0]}%3A{google_1s[1]}\"\n",
    "            else:\n",
    "                return None, None\n",
    "            \n",
    "            # 取得身分驗證的KEI碼 在<head><script>中\n",
    "            html = self.driver.page_source\n",
    "            soup = bs(html, \"lxml\")\n",
    "            # 取得第一個匹配結果\n",
    "            google_kei_code = next((script.text.split(\"kEI='\", 1)[1].split(\"'\", 1)[0] for script in soup.find_all(\"script\") if \"kEI\" in script.text), None)\n",
    "\n",
    "            return google_1s_code, google_kei_code\n",
    "        except:\n",
    "            print(f\"無法獲得1s碼\")\n",
    "            return None, None\n",
    "    \n",
    "    # 儲存當下的 google_2s 因應突發狀況\n",
    "    def save_google_2s_checkpoint(self, google_2s, location):\n",
    "        with open(self.checkpoint_file, 'w', encoding='utf-8') as file:\n",
    "            json.dump({\"google_2s\": google_2s, \"location\": location}, file)\n",
    "\n",
    "    # 接續上次的 google_2s 與地點 如果沒有則返回 None\n",
    "    def load_google_2s_checkpoint(self):\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            with open(self.checkpoint_file, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                return data.get(\"google_2s\"), data.get(\"location\")\n",
    "        return None, None    \n",
    "    \n",
    "    # 抓取並寫入評論\n",
    "    def fetch_reviews(self, google_1s, google_kei, location):\n",
    "        # 讀取上次中斷爬取地點與2s碼\n",
    "        google_2s, last_location = self.load_google_2s_checkpoint()\n",
    "        # 如果是新的地點，則重置 google_2s 為空值\n",
    "        if last_location != location:\n",
    "            google_2s = \"\"\n",
    "        # 不重複的評論ID\n",
    "        unique_ids = set()\n",
    "        # 總評論數\n",
    "        total_reviews = 0\n",
    "        # 有留言的評論數\n",
    "        reviews_with_comments = 0\n",
    "        # 頁數\n",
    "        count = 1\n",
    "        # 評論輸出檔名\n",
    "        output_file = f\"reviews_output_{location}.csv\"\n",
    "        \n",
    "        while True:\n",
    "            url = f'https://www.google.com/maps/rpc/listugcposts?authuser=0&hl=zh-TW&gl=tw&pb=!1m6!1s{google_1s}!6m4!4m1!1e1!4m1!1e3!2m2!1i10!2s{google_2s}!5m2!1s{google_kei}!7e81!8m9!2b1!3b1!5b1!7b1!12m4!1b1!2b1!4m1!1e1!11m0!13m1!1e2'\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            raw_content = response.text.strip()\n",
    "            \n",
    "            # 處理防爬蟲字串\n",
    "            if raw_content.startswith(\")]}'\"):\n",
    "                raw_content = raw_content[4:]\n",
    "            \n",
    "            # 轉為json格式\n",
    "            data = json.loads(raw_content)\n",
    "            \n",
    "\n",
    "            # 輸出每一頁評論\n",
    "            with open(output_file, mode='a', encoding='utf-8', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                for review in data[2]:\n",
    "                    try:\n",
    "                        user = review[0][1][4][5][0]\n",
    "                        user_id = review[0][1][4][5][3]\n",
    "                        user_page = review[0][1][4][2][0]\n",
    "                        review_id = str(review[0][0])\n",
    "                        rating = str(review[0][2][0][0])\n",
    "                        timestamp = datetime.fromtimestamp(review[0][1][2] // 1000000, tz=timezone.utc).strftime('%Y-%m-%d')\n",
    "                        \n",
    "                        # 只有評分的評論內容相關變數都要清空\n",
    "                        try:\n",
    "                            comment = review[0][2][15][0][0]\n",
    "                        except:\n",
    "                            comment = \"\"\n",
    "\n",
    "                        try:                   \n",
    "                            language = review[0][2][14][0]\n",
    "                        except:\n",
    "                            language = \"\"\n",
    "\n",
    "                        try:\n",
    "                            translated_comment = review[0][2][15][1][0]\n",
    "                        except:\n",
    "                            translated_comment = \"\"\n",
    "\n",
    "                        # 評論ID不重複才寫入\n",
    "                        if review_id not in unique_ids:\n",
    "                            writer.writerow([user, user_id,review_id, rating, timestamp, comment, language, translated_comment,user_page])\n",
    "                            unique_ids.add(review_id)\n",
    "                            total_reviews += 1\n",
    "                            if comment.strip():\n",
    "                                reviews_with_comments += 1\n",
    "                    except:\n",
    "                        print(f\"無法該筆爬取評論\")\n",
    "            print(f\"現在在第 {count} 頁\")\n",
    "            print(f\"總共存入 {total_reviews} 筆評論\")\n",
    "            print(f\"其中有 {reviews_with_comments} 筆評論有內文\")\n",
    "            count += 1\n",
    "\n",
    "            # 處理2s碼\n",
    "            try:\n",
    "                google_2s = data[1].replace('=', '%3D')\n",
    "            except:\n",
    "                print(\"沒有下一頁\")\n",
    "                break\n",
    "            \n",
    "            # 儲存最新的 google_2s\n",
    "            self.save_google_2s_checkpoint(google_2s, location)\n",
    "            \n",
    "        if total_reviews == 0:\n",
    "            self.log_failed_location(location, \"沒有任何評論\")\n",
    "\n",
    "    def scrape_from_csv(self, input_file):\n",
    "        with open(input_file, mode='r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            locations = list(csv_reader)\n",
    "        for row in locations:\n",
    "            if row:\n",
    "                location = row[0]\n",
    "                print(f\"開始爬取 {location}\")\n",
    "                url = self.search_location(location)\n",
    "                if url:\n",
    "                    google_1s, google_kei = self.extract_google_codes(url)\n",
    "                    if google_1s and google_kei:\n",
    "                        self.fetch_reviews(google_1s, google_kei, location)\n",
    "                        print(f'{location} 已爬取完成')\n",
    "                    else:\n",
    "                        self.log_failed_location(location, \"無法獲得1s碼\")\n",
    "\n",
    "    # 關閉瀏覽器\n",
    "    def close_driver(self):\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開啟瀏覽器\n",
    "scraper = GoogleMapScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實際爬蟲步驟 只需要給location list 的 csv檔\n",
    "scraper.scrape_from_csv(\"google_maps_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等確定擷取流程結束後，再手動關閉瀏覽器，以便 debug，減少瀏覽器開開關關\n",
    "scraper.close_driver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
